{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b5877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone\n",
      "  Using cached pinecone-6.0.2-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pinecone) (2025.1.31)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
      "  Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pinecone) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Using cached pinecone-6.0.2-py3-none-any.whl (421 kB)\n",
      "Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: pinecone-plugin-interface, pinecone\n",
      "Successfully installed pinecone-6.0.2 pinecone-plugin-interface-0.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5ab39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9694ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb264043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pinecone_cloud = os.getenv(\"PINECONE_CLOUD\")  # usually \"aws\" or \"gcp\"\n",
    "pinecone_region = os.getenv(\"PINECONE_REGION\")  # like \"us-west-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(\n",
    "    api_key=pinecone_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"career-paths\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"career-paths-ex6oxxq.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 1536,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.create_index(\n",
    "    name=\"career-paths\",\n",
    "    dimension=1536,  # depends on your embeddings\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=pinecone_cloud,   # 'aws' or 'gcp'\n",
    "        region=pinecone_region  # like 'us-west-2'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3ea0f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-pinecone\n",
      "  Downloading langchain_pinecone-0.2.5-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langchain-pinecone) (0.3.51)\n",
      "Requirement already satisfied: pinecone<7.0.0,>=6.0.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (6.0.2)\n",
      "Collecting aiohttp<3.11,>=3.10 (from langchain-pinecone)\n",
      "  Downloading aiohttp-3.10.11-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.4 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langchain-pinecone) (2.2.4)\n",
      "Collecting langchain-tests<1.0.0,>=0.3.7 (from langchain-pinecone)\n",
      "  Downloading langchain_tests-0.3.19-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (6.4.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.19.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.3.17)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.10.6)\n",
      "Collecting langchain-core<1.0.0,>=0.3.34 (from langchain-pinecone)\n",
      "  Using cached langchain_core-0.3.56-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting pytest<9,>=7 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pytest-8.3.5-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pytest-asyncio<1,>=0.20 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pytest_asyncio-0.26.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.28.1)\n",
      "Collecting syrupy<5,>=4 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading syrupy-4.9.1-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting pytest-socket<1,>=0.6.0 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pytest_socket-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2025.1.31)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2.3.0)\n",
      "Requirement already satisfied: anyio in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.0.7)\n",
      "Requirement already satisfied: idna in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.27.2)\n",
      "Requirement already satisfied: colorama in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.4.6)\n",
      "Collecting iniconfig (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (1.17.0)\n",
      "Requirement already satisfied: propcache>=0.2.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.10->langchain-pinecone) (0.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.3.1)\n",
      "Downloading langchain_pinecone-0.2.5-py3-none-any.whl (16 kB)\n",
      "Downloading aiohttp-3.10.11-cp311-cp311-win_amd64.whl (382 kB)\n",
      "Downloading langchain_tests-0.3.19-py3-none-any.whl (40 kB)\n",
      "Using cached langchain_core-0.3.56-py3-none-any.whl (437 kB)\n",
      "Downloading pytest-8.3.5-py3-none-any.whl (343 kB)\n",
      "Downloading pytest_asyncio-0.26.0-py3-none-any.whl (19 kB)\n",
      "Downloading pytest_socket-0.7.0-py3-none-any.whl (6.8 kB)\n",
      "Downloading syrupy-4.9.1-py3-none-any.whl (52 kB)\n",
      "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
      "Installing collected packages: pluggy, iniconfig, pytest, aiohttp, syrupy, pytest-socket, pytest-asyncio, langchain-core, langchain-tests, langchain-pinecone\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.11.16\n",
      "    Uninstalling aiohttp-3.11.16:\n",
      "      Successfully uninstalled aiohttp-3.11.16\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.51\n",
      "    Uninstalling langchain-core-0.3.51:\n",
      "      Successfully uninstalled langchain-core-0.3.51\n",
      "Successfully installed aiohttp-3.10.11 iniconfig-2.1.0 langchain-core-0.3.56 langchain-pinecone-0.2.5 langchain-tests-0.3.19 pluggy-1.5.0 pytest-8.3.5 pytest-asyncio-0.26.0 pytest-socket-0.7.0 syrupy-4.9.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pinecone 6.0.2 does not provide the extra 'async'\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be9a1204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using openai embedding to convert job roles into vector and store in pinecone\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de1361e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cf011e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "df = pd.read_csv(\"cleaned_job_skills.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e7852ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Role</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Experience</th>\n",
       "      <th>Skills/Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>UPL</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>3-6</td>\n",
       "      <td>python, MLT, statistical modeling, machine lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-9</td>\n",
       "      <td>Data Science, Machine learning, Python, Azure,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Applied Data Scientist / ML Senior Engineer (P...</td>\n",
       "      <td>SAP India Pvt.Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-10</td>\n",
       "      <td>Python, IT Skills, Testing, Cloud, Product Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>UPL</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>1-4</td>\n",
       "      <td>python, machine learning, Data Science, data a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-8</td>\n",
       "      <td>IT Skills, Python, Data Science, Machine Learn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_Role            Company  \\\n",
       "0                              Senior Data Scientist                UPL   \n",
       "1                              Senior Data Scientist            Walmart   \n",
       "2  Applied Data Scientist / ML Senior Engineer (P...  SAP India Pvt.Ltd   \n",
       "3                                     Data Scientist                UPL   \n",
       "4                                     Data Scientist            Walmart   \n",
       "\n",
       "                                  Location Job Experience  \\\n",
       "0  Bangalore/Bengaluru, Mumbai (All Areas)            3-6   \n",
       "1                      Bangalore/Bengaluru            5-9   \n",
       "2                      Bangalore/Bengaluru           5-10   \n",
       "3  Bangalore/Bengaluru, Mumbai (All Areas)            1-4   \n",
       "4                      Bangalore/Bengaluru            4-8   \n",
       "\n",
       "                                  Skills/Description  \n",
       "0  python, MLT, statistical modeling, machine lea...  \n",
       "1  Data Science, Machine learning, Python, Azure,...  \n",
       "2  Python, IT Skills, Testing, Cloud, Product Man...  \n",
       "3  python, machine learning, Data Science, data a...  \n",
       "4  IT Skills, Python, Data Science, Machine Learn...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38578a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df[\"Job_Role\"]+\": \"+ df[\"Skills/Description\"]+\": \"+df[\"Company\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30320681",
   "metadata": {},
   "source": [
    "Our documents payload is too large for Pinecone's input size limits.So, we will do chunking to break the size of\n",
    "document in order to fit it in pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cd88791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "# chunk each document\n",
    "chunked_documents = []\n",
    "for doc in documents:\n",
    "    chunks = text_splitter.split_text(doc)\n",
    "    chunked_documents.extend(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [13:26<00:00,  3.36s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Create the vector store object from the existing index.\n",
    "vector_store = PineconeVectorStore.from_existing_index(\n",
    "    index_name=\"career-paths\",\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "batch_size = 50  # Adjust as needed\n",
    "for i in tqdm(range(0, len(chunked_documents), batch_size)):\n",
    "    batch = chunked_documents[i:i + batch_size]\n",
    "    for attempt in range(3):  # Retry up to 3 times\n",
    "        try:\n",
    "            vector_store.add_texts(batch)\n",
    "            break  # Success; exit the retry loop for this batch.\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Batch {i}-{i+batch_size} failed on attempt {attempt + 1}: {e}\")\n",
    "            time.sleep(5)  # Wait before retrying.\n",
    "    else:\n",
    "        print(f\"❌ Batch {i}-{i+batch_size} failed after 3 retries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1b84dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbformat\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat)\n",
      "  Downloading fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: jsonschema>=2.6 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.24.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (310)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.12.2)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: fastjsonschema, nbformat\n",
      "Successfully installed fastjsonschema-2.21.1 nbformat-5.10.4\n"
     ]
    }
   ],
   "source": [
    "!pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df8b361b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Gen AI\\LangChain\\venv\\Lib\\site-packages\\nbformat\\__init__.py:96: MissingIDFieldWarning: Cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyresparser in d:\\gen ai\\langchain\\venv\\lib\\site-packages (1.0.6)\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (25.3.0)\n",
      "Requirement already satisfied: blis>=0.2.4 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2019.6.16 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (2025.1.31)\n",
      "Requirement already satisfied: chardet>=3.0.4 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (5.2.0)\n",
      "Requirement already satisfied: cymem>=2.0.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (2.0.11)\n",
      "Requirement already satisfied: docx2txt>=0.7 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (0.9)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (3.10)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (4.23.0)\n",
      "Requirement already satisfied: nltk>=3.4.3 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.16.4 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (2.2.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (2.2.3)\n",
      "Requirement already satisfied: pdfminer.six>=20181108 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (20250327)\n",
      "Requirement already satisfied: preshed>=2.0.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (3.0.9)\n",
      "Requirement already satisfied: pycryptodome>=3.8.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (3.22.0)\n",
      "Requirement already satisfied: pyrsistent>=0.15.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (0.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2019.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (2025.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (2.32.3)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (1.17.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.1.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (2.4.0)\n",
      "Requirement already satisfied: spacy>=2.1.4 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (3.8.5)\n",
      "Requirement already satisfied: srsly>=0.0.7 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (2.5.1)\n",
      "Requirement already satisfied: thinc>=7.0.4 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (8.3.6)\n",
      "Requirement already satisfied: tqdm>=4.32.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (2.3.0)\n",
      "Requirement already satisfied: wasabi>=0.2.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pyresparser) (1.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from jsonschema>=3.0.1->pyresparser) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from jsonschema>=3.0.1->pyresparser) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from jsonschema>=3.0.1->pyresparser) (0.24.0)\n",
      "Requirement already satisfied: click in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from nltk>=3.4.3->pyresparser) (8.1.8)\n",
      "Requirement already satisfied: joblib in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from nltk>=3.4.3->pyresparser) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from nltk>=3.4.3->pyresparser) (2024.11.6)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pandas>=0.24.2->pyresparser) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pdfminer.six>=20181108->pyresparser) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pdfminer.six>=20181108->pyresparser) (44.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from preshed>=2.0.1->pyresparser) (1.0.12)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (1.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (0.15.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy>=2.1.4->pyresparser) (3.5.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from thinc>=7.0.4->pyresparser) (0.1.5)\n",
      "Requirement already satisfied: colorama in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from tqdm>=4.32.2->pyresparser) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (1.17.1)\n",
      "Requirement already satisfied: language-data>=1.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.1.4->pyresparser) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.4->pyresparser) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.4->pyresparser) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.4->pyresparser) (4.12.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=2.1.4->pyresparser) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy>=2.1.4->pyresparser) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.1.4->pyresparser) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.1.4->pyresparser) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from jinja2->spacy>=2.1.4->pyresparser) (3.0.2)\n",
      "Requirement already satisfied: pycparser in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20181108->pyresparser) (2.22)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.1.4->pyresparser) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.4->pyresparser) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.4->pyresparser) (2.19.1)\n",
      "Requirement already satisfied: wrapt in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=2.1.4->pyresparser) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.4->pyresparser) (0.1.2)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 6.7 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.2/12.8 MB 14.0 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 16.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.6/12.8 MB 16.8 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 16.1 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: pdfplumber in d:\\gen ai\\langchain\\venv\\lib\\site-packages (0.11.6)\n",
      "Requirement already satisfied: pdfminer.six==20250327 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pdfplumber) (20250327)\n",
      "Requirement already satisfied: Pillow>=9.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pdfplumber) (11.2.1)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (44.0.2)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
      "Requirement already satisfied: spacy in d:\\gen ai\\langchain\\venv\\lib\\site-packages (3.8.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (2.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\gen ai\\langchain\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed Resume Data:\n",
      "name: Kushagra Srivastava\n",
      "email: kushagra843srivastava@gmail.com\n",
      "phone: 9555009525\n",
      "skills: ['Python', 'Java', 'JavaScript', 'SQL', 'Machine Learning', 'NLP', 'Data Science', 'Excel', 'Power BI', 'Pandas', 'Git', 'GitHub']\n",
      "experience: [{'position': 'Data Science Intern, Agrix y 2024', 'company': '', 'date': 'May 2024 – Jul', 'description': '\\uf0b7 Revolutionized agriculture with predictive Python models, boosting yields and reducing losses by up to 75 %.\\n\\uf0b7 Developed interactive dashboards using Power BI, Excel, and Python to visualize KPIs, resulting in a 30% reduction in\\nreport preparation time and empowering stakeholders with real-time insights for strategic decisions.\\n\\uf0b7 Analyzed agricultural reports and datasets with Seaborn and Matplotlib, transforming complex data into actionable insights\\non crop health, soil conditions, and market trends; increased yield prediction accuracy by 25% and stakeholder understanding\\nby 40%.\\n\\uf0b7 Utilized data preprocessing techniques and maintained databases with Python and SQL, collaborating with teams to integrate\\ndata insights and drive business growth and operational efficiency leading to increase in growth by 5%.'}]\n",
      "education: ['\\uf0b7 Utilized data preprocessing techniques and maintained databases with Python and SQL, collaborating with teams to integrate data insights and drive business growth and operational efficiency leading to increase in growth by 5%.', 'Bachelor of Engineering (Computer Science) December 2021 -August 2025 Birla Institute Of Technology, Mesra CGPA 7.6/10', 'Class 12th - CBSE March 2020 – May 2021 GN National Public School, Gorakhpur Percentage - 90%', 'Class 10th - CBSE May 2018 – May 2019 GN National Public School, Gorakhpur Percentage – 93%']\n",
      "Skills: Python, Java, JavaScript, SQL, Machine Learning, NLP, Data Science, Excel, Power BI, Pandas, Git, GitHub\n",
      "Experience: Data Science Intern, Agrix y 2024 (May 2024 – Jul)\n",
      "Education:  Utilized data preprocessing techniques and maintained databases with Python and SQL, collaborating with teams to integrate data insights and drive business growth and operational efficiency leading to increase in growth by 5%., Bachelor of Engineering (Computer Science) December 2021 -August 2025 Birla Institute Of Technology, Mesra CGPA 7.6/10, Class 12th - CBSE March 2020 – May 2021 GN National Public School, Gorakhpur Percentage - 90%, Class 10th - CBSE May 2018 – May 2019 GN National Public School, Gorakhpur Percentage – 93%\n"
     ]
    }
   ],
   "source": [
    "%run resume_parse.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ce654f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = resume_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9867bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search(query, k=3)  # Get top 3 matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9018ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Job Roles: ['Data Scientist V', 'Data Scientist V', 'Data Scientist Intern']\n"
     ]
    }
   ],
   "source": [
    "# Extract job roles\n",
    "job_roles = [result.page_content.split(\":\")[0] for result in results]\n",
    "print(\"Recommended Job Roles:\", job_roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa1e9f",
   "metadata": {},
   "source": [
    "#### Now we will set up our llm in order to generate roadmap to qualify for these jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4390f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"), model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f29d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Based on the following resume:\n",
    "    {resume}\n",
    "\n",
    "    And the recommended job roles: {job_roles}\n",
    "\n",
    "    Generate a personalized learning roadmap to help the user transition to one of these roles.\n",
    "    Include specific courses, certifications, and projects they should pursue.\n",
    "    \"\"\",\n",
    "    input_variables=[\"resume\", \"job_roles\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbb52ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chain\n",
    "chain = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32437e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Roadmap:\n",
      " Personalized Learning Roadmap to Transition to a Data Scientist Role:\n",
      "\n",
      "1. Enhance Python Skills:\n",
      "   - Take online courses such as \"Python for Data Science and Machine Learning Bootcamp\" on Udemy\n",
      "   - Complete certification in Python programming on platforms like Coursera or edX\n",
      "\n",
      "2. Improve Data Science Skills:\n",
      "   - Enroll in a course on \"Data Science and Machine Learning Bootcamp with R\" to expand your data science knowledge\n",
      "   - Obtain a certification in Data Science from reputable organizations like IBM or Harvard University\n",
      "\n",
      "3. Master Machine Learning and NLP:\n",
      "   - Take courses on Machine Learning and Natural Language Processing on platforms like Coursera or DataCamp\n",
      "   - Work on projects related to Machine Learning and NLP to showcase your skills\n",
      "\n",
      "4. Further SQL Proficiency:\n",
      "   - Complete advanced SQL courses on platforms like Codecademy or Khan Academy\n",
      "   - Obtain certifications in SQL querying and database management\n",
      "\n",
      "5. Gain Experience in Excel and Power BI:\n",
      "   - Participate in projects that involve data visualization using Excel and Power BI\n",
      "   - Explore online resources and tutorials to improve your skills in Excel and Power BI\n",
      "\n",
      "6. Utilize Pandas for Data Manipulation:\n",
      "   - Practice using Pandas library for data manipulation tasks\n",
      "   - Work on real-life projects that involve data cleaning and analysis using Pandas\n",
      "\n",
      "7. Strengthen Git and GitHub skills:\n",
      "   - Learn about version control using Git through online tutorials and courses\n",
      "   - Contribute to open-source projects on GitHub to demonstrate your proficiency\n",
      "\n",
      "By following this learning roadmap and actively working on projects to apply your skills, you will be well-prepared to transition into a Data Scientist role. Remember to continuously seek opportunities for growth and development in the field of Data Science.\n"
     ]
    }
   ],
   "source": [
    "# Run the chain\n",
    "roadmap = chain.invoke({\"resume\": resume_text, \"job_roles\": \", \".join(job_roles)})\n",
    "print(\"Learning Roadmap:\\n\", roadmap.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b83839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "    {\n",
       "        \"name\": \"your-index-name\",\n",
       "        \"metric\": \"cosine\",\n",
       "        \"host\": \"your-index-name-ex6oxxq.svc.aped-4627-b74a.pinecone.io\",\n",
       "        \"spec\": {\n",
       "            \"serverless\": {\n",
       "                \"cloud\": \"aws\",\n",
       "                \"region\": \"us-east-1\"\n",
       "            }\n",
       "        },\n",
       "        \"status\": {\n",
       "            \"ready\": true,\n",
       "            \"state\": \"Ready\"\n",
       "        },\n",
       "        \"vector_type\": \"dense\",\n",
       "        \"dimension\": 1536,\n",
       "        \"deletion_protection\": \"disabled\",\n",
       "        \"tags\": null\n",
       "    },\n",
       "    {\n",
       "        \"name\": \"career-paths\",\n",
       "        \"metric\": \"cosine\",\n",
       "        \"host\": \"career-paths-ex6oxxq.svc.aped-4627-b74a.pinecone.io\",\n",
       "        \"spec\": {\n",
       "            \"serverless\": {\n",
       "                \"cloud\": \"aws\",\n",
       "                \"region\": \"us-east-1\"\n",
       "            }\n",
       "        },\n",
       "        \"status\": {\n",
       "            \"ready\": true,\n",
       "            \"state\": \"Ready\"\n",
       "        },\n",
       "        \"vector_type\": \"dense\",\n",
       "        \"dimension\": 1536,\n",
       "        \"deletion_protection\": \"disabled\",\n",
       "        \"tags\": null\n",
       "    }\n",
       "]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = pc.list_indexes()\n",
    "print(indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bfa42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
